name: Train evaluate model
description: Train a classification model on the training data.
inputs:
- {name: training_data, type: Dataset, description: Training data as a KFP Dataset
    object.}
- name: validation_data
  type: Dataset
  description: |-
    Validation data (used to prevent overfitting)
    as a KFP Dataset object.
- {name: target_column, type: String, description: Column containing the target column
    for classification.}
- name: model_name
  type: String
  description: |-
    Name of the classifier that will be trained. Must be one of
    'logistic_regression', 'sgd_classifier', 'random_forest', 'lightgbm',
    'xgboost'.
- {name: models_params, type: JsonObject, description: Hyperparameters of the model.
    Default to an empty dict., default: '{}', optional: true}
- name: fit_args
  type: JsonObject
  description: |-
    Arguments used when fitting the model.
    Default to an empty dict.
  default: '{}'
  optional: true
- name: data_processing_args
  type: JsonObject
  description: |-
    Arguments used when running extra processing on
    the data (such as scaling or oversampling). Default to an empty dict.
  default: '{}'
  optional: true
- {name: model_gcs_folder_path, type: String, optional: true}
outputs:
- {name: train_metrics, type: Metrics, description: ''}
- {name: valid_metrics, type: Metrics, description: ''}
- {name: valid_pr_curve, type: Artifact}
- name: model
  type: Model
  description: |-
    Output model as a KFP Model object, this parameter
    will be passed automatically by the orchestrator. The .path
    attribute is the location of the joblib file in GCS.
implementation:
  container:
    image: europe-west2-docker.pkg.dev/robertofierimonte-ml-pipe/docker-repo/credit-card-frauds:latest
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-storage==2.9.0' 'matplotlib==3.5.1' 'kfp==1.8.22' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - |2+

      import kfp
      from kfp.v2 import dsl
      from kfp.v2.dsl import *
      from typing import *

      def train_evaluate_model(
          training_data: Input[Dataset],
          validation_data: Input[Dataset],
          target_column: str,
          model_name: str,
          train_metrics: Output[Metrics],
          valid_metrics: Output[Metrics],
          valid_pr_curve: Output[Artifact],
          model: Output[Model],
          models_params: dict = {},
          fit_args: dict = {},
          data_processing_args: dict = {},
          model_gcs_folder_path: str = None,
      ) -> None:
          """Train a classification model on the training data.

          Args:
              training_data (Input[Dataset]): Training data as a KFP Dataset object.
              validation_data (Input[Dataset]): Validation data (used to prevent overfitting)
                  as a KFP Dataset object.
              target_column (str): Column containing the target column for classification.
              model_name (str): Name of the classifier that will be trained. Must be one of
                  'logistic_regression', 'sgd_classifier', 'random_forest', 'lightgbm',
                  'xgboost'.
              models_params (dict): Hyperparameters of the model. Default to an empty dict.
              fit_args (dict): Arguments used when fitting the model.
                  Default to an empty dict.
              data_processing_args (dict): Arguments used when running extra processing on
                  the data (such as scaling or oversampling). Default to an empty dict.
              train_metrics (Output[Metrics]):
              valid_metrics (Output[Metrics]):
              model (Output[Model]): Output model as a KFP Model object, this parameter
                  will be passed automatically by the orchestrator. The .path
                  attribute is the location of the joblib file in GCS.
          """
          import os
          from pathlib import Path

          import joblib
          import pandas as pd
          from google.cloud import storage
          from lightgbm import LGBMClassifier
          from loguru import logger
          from sklearn.ensemble import RandomForestClassifier
          from sklearn.linear_model import LogisticRegression, SGDClassifier
          from xgboost import XGBClassifier

          from src.base.model import evaluate_model, train_model
          from src.base.visualisation import plot_precision_recall_curve

          df_train = pd.read_parquet(training_data.path)
          df_train = df_train.drop(columns=["transaction_id"])
          y_train = df_train.pop(target_column)
          logger.info(f"Loaded training data, shape {df_train.shape}.")

          df_valid = pd.read_parquet(validation_data.path)
          df_valid = df_valid.drop(columns=["transaction_id"])
          y_valid = df_valid.pop(target_column)
          logger.info(f"Loaded evaluation data, shape {df_valid.shape}.")

          use_eval_set = False
          model_params = models_params.get(model_name, {})
          if model_name == "logistic_regression":
              classifier = LogisticRegression(random_state=42, **model_params)
          elif model_name == "sgd_classifier":
              classifier = SGDClassifier(random_state=42, **model_params)
          elif model_name == "random_forest":
              classifier = RandomForestClassifier(random_state=42, **model_params)
          elif model_name == "lightgbm":
              classifier = LGBMClassifier(random_state=42, **model_params)
              use_eval_set = True
          elif model_name == "xgboost":
              classifier = XGBClassifier(
                  use_label_encoder=False, random_state=42, **model_params
              )
              use_eval_set = True
          else:
              msg = (
                  "`model_name` must be one of 'logistic_regression', 'sgd_classifier', "
                  "'random_forest', 'lightgbm', 'xgboost'."
              )
              logger.error(msg)
              raise ValueError(msg)

          logger.info(f"Training model {model_name}.")
          classifier, training_metrics = train_model(
              classifier,
              X_train=df_train,
              y_train=y_train,
              X_valid=df_valid,
              y_valid=y_valid,
              use_eval_set=use_eval_set,
              fit_args=fit_args.get(model_name, {}),
              **data_processing_args,
          )
          logger.info("Training completed.")
          logger.debug(f"Type of classifier: {type(classifier)}.")
          logger.debug(f"Classifier: {classifier}.")
          for k, v in training_metrics.items():
              if k != "Precision Recall Curve":
                  train_metrics.log_metric(k, v)

          validation_metrics, _, _ = evaluate_model(classifier, df_valid, y_valid)
          logger.info("Evaluation completed.")
          for k, v in validation_metrics.items():
              if k != "Precision Recall Curve":
                  valid_metrics.log_metric(k, v)

          logger.debug(f"Type of classifier: {type(classifier)}.")
          logger.debug(f"Classifier: {classifier}.")

          if model_gcs_folder_path is not None:
              model.path = model_gcs_folder_path
              valid_pr_curve.path = model_gcs_folder_path

          model.path = model.path + f"/{model_name}"
          model_dir = Path(model.path).parent.absolute()
          os.makedirs(model_dir, exist_ok=True)

          logger.info(f"Saving model to {model.path}.")
          joblib.dump(classifier, model.path)

          valid_pr_curve.path = (
              valid_pr_curve.path + f"/precision_recall_curve_{model_name}.png"
          )
          _ = plot_precision_recall_curve(
              model=classifier,
              model_name=model_name,
              X=df_valid,
              y=y_valid,
              save_path=valid_pr_curve.path,
          )

          client = storage.Client()
          logger.debug(f"URI: {valid_pr_curve.uri}")
          logger.debug(f"Path: {valid_pr_curve.path}")

    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - train_evaluate_model
