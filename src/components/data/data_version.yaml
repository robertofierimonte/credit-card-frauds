name: Get data version
description: Get data version to use in the pipeline.
inputs:
- {name: payload_data_version, type: String, description: Data version provided in
    the payload file.}
- {name: project_id, type: String, description: Bigquery project ID.}
- name: dataset_id
  type: String
  description: |-
    Bigquery dataset ID. This function will look for the
    most recent BQ dataset that has the pattern of
    {dataset_id}_%Y%m%dT%H%M%S.
- name: dataset_location
  type: String
  description: |-
    Bigquery dataset location.
    Defaults to "europe-west2".
  default: europe-west2
  optional: true
outputs:
- {name: Output, type: String}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==3.11.0' 'loguru==0.7.0' 'kfp==1.8.22' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - |2+

      import kfp
      from kfp.v2 import dsl
      from kfp.v2.dsl import *
      from typing import *

      def get_data_version(
          payload_data_version: str,
          project_id: str,
          dataset_id: str,
          dataset_location: str = "europe-west2",
      ) -> str:
          """Get data version to use in the pipeline.

          Args:
              payload_data_version (str): Data version provided in the payload file.
              project_id (str): Bigquery project ID.
              dataset_id (str): Bigquery dataset ID. This function will look for the
                  most recent BQ dataset that has the pattern of
                  {dataset_id}_%Y%m%dT%H%M%S.
              dataset_location (str, optional): Bigquery dataset location.
                  Defaults to "europe-west2".
          """
          import re

          from google.cloud import bigquery
          from loguru import logger

          if payload_data_version == "":
              bq_client = bigquery.client.Client(
                  project=project_id, location=dataset_location
              )
              datasets = [d.dataset_id for d in list(bq_client.list_datasets())]
              matches = [
                  re.search(rf"(?<={dataset_id}_)(\d{{8}}T\d{{6}})", d) for d in datasets
              ]
              versions = sorted([m.group(0) for m in matches if m is not None])
              logger.debug(f"Found {len(versions)} versions of the data.")

              try:
                  res = versions[-1]
                  logger.info(f"Most recent data version retrieved: {res}.")
                  return res
              except IndexError as e:
                  logger.error(
                      f"No datasets matching the expected pattern in project {project_id}."
                  )
                  raise e
          else:
              logger.info(f"Data version {payload_data_version} provided in payload.")
              return payload_data_version

    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - get_data_version
