name: Generate training stats schema
description: _summary_
inputs:
- {name: training_data, type: Dataset, description: _description_}
- {name: target_column, type: String, description: _description_}
- {name: artifacts_gcs_folder_path, type: String, description: _description_. Defaults
    to None., optional: true}
outputs:
- {name: training_stats, type: Artifact, description: _description_}
- {name: training_schema, type: Artifact, description: _description_}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pyarrow==6.0.1' 'pandas==1.4.3' 'tensorflow-data-validation==1.13.0' 'kfp==1.8.22' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - |2+

      import kfp
      from kfp.v2 import dsl
      from kfp.v2.dsl import *
      from typing import *

      def generate_training_stats_schema(
          training_data: Input[Dataset],
          training_stats: Output[Artifact],
          training_schema: Output[Artifact],
          target_column: str,
          artifacts_gcs_folder_path: str = None
      ) -> None:
          """_summary_

          Args:
              training_data (Input[Dataset]): _description_
              training_stats (Output[Artifact]): _description_
              training_schema (Output[Artifact]): _description_
              target_column (str): _description_
              artifacts_gcs_folder_path (str, optional): _description_. Defaults to None.
          """
          from pathlib import Path

          import pandas as pd
          import tensorflow_data_validation as tfdv

          df_train = pd.read_parquet(training_data.path)
          df_train = df_train.drop(columns=["transaction_id"])
          stats_train = tfdv.generate_statistics_from_dataframe(df_train)
          schema_train = tfdv.infer_schema(stats_train)
          schema_train.default_environment.append("TRAINING")
          schema_train.default_environment.append("SERVING")

          tfdv.get_feature(schema_train, target_column).not_in_environment.append("SERVING")

          if artifacts_gcs_folder_path is not None:
              training_stats.path = artifacts_gcs_folder_path
              training_schema.path = artifacts_gcs_folder_path

          training_stats.path = str(Path(training_stats.path) / "training_stats.pbtxt")
          directory = Path(training_stats.path).parent.absolute()
          directory.mkdir(parents=True, exist_ok=True)

          training_schema.path = str(Path(training_schema.path) / "training_schema.pbtxt")
          directory = Path(training_schema.path).parent.absolute()
          directory.mkdir(parents=True, exist_ok=True)

          tfdv.write_stats_text(stats_train, training_stats.path)
          tfdv.write_schema_text(schema_train, training_schema.path)

    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - generate_training_stats_schema
