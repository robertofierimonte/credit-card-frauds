{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c01a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# allow more data columns to be shown than by default\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc20d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc27cae2",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcd42d4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a376194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction data\n",
    "cwd_path = os.path.abspath(os.getcwd())\n",
    "project_root = os.path.dirname(cwd_path)\n",
    "data_path = os.path.join(project_root, 'data/credit_card_transactions-ibm_v2.csv')\n",
    "transactions = pd.read_csv(data_path)\n",
    "display(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the original data\n",
    "transactions_original = transactions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f968bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a random subset of the original data with a smaller size, makes initial data exploration faster \n",
    "sample_size = 10**6\n",
    "transactions = transactions_original.sample(sample_size, random_state=42)\n",
    "display(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c63b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# card data\n",
    "data_path = os.path.join(project_root, 'data/sd254_cards.csv')\n",
    "cards = pd.read_csv(data_path)\n",
    "# renanme CARD INDEX to match other data sources\n",
    "cards = cards.rename(columns={'CARD INDEX':'Card'})\n",
    "display(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user data\n",
    "data_path = os.path.join(project_root, 'data/sd254_users.csv')\n",
    "users = pd.read_csv(data_path)\n",
    "# add User as a column\n",
    "users['User'] = users.index\n",
    "display(users)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d4fda5f",
   "metadata": {},
   "source": [
    "# MERGE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c51538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge transactions and card data\n",
    "data = transactions.merge(cards, how='inner', on=['User', 'Card'])\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b9b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge user data\n",
    "data = data.merge(users, how='inner', on='User')\n",
    "display(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c218f7f3",
   "metadata": {},
   "source": [
    "# DATA WRANGLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    n_unique = data[col].nunique()\n",
    "    print(f'Number of unique values in {col}: {n_unique}')\n",
    "    if n_unique<=10:\n",
    "        print(f'The unique values in column {col}')\n",
    "        print(data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94bd7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Is Fraud?\"] = [1 if x == \"Yes\" else 0 for x in data[\"Is Fraud?\"]]\n",
    "data['Is Fraud?'].sum() / data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT ENCODING for the different transaction types\n",
    "one_hot_encoder = OneHotEncoder(sparse=False).fit(np.array(data['Use Chip']).reshape(-1,1))\n",
    "new_columns = [col[3:] for col in one_hot_encoder.get_feature_names()]\n",
    "data[new_columns] = one_hot_encoder.transform(np.array(data['Use Chip']).reshape(-1,1))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add DATETIME (no timezone info given)\n",
    "data[\"Datetime\"] = data.apply(lambda row: \n",
    "                          dt.datetime(row[\"Year\"], row[\"Month\"], row[\"Day\"], int(row[\"Time\"][0:2]), int(row[\"Time\"][3:5])), \n",
    "                          axis=1)\n",
    "# sort data by datetime\n",
    "data = data.sort_values(by='Datetime')\n",
    "# reindex dataframe\n",
    "data = (data\n",
    "        .reset_index()\n",
    "        .rename(columns={'index':'transaction_index'})\n",
    "       )\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4a0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change transaction AMOUNT from string to float\n",
    "data['Amount'] = data['Amount'].str.replace('$','').astype(float)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4cbac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-1 encoding of \"Is Fraud?\" \n",
    "fraud_encoding = {'No':0, 'Yes':1}\n",
    "# data['Is Fraud?'] = data['Is Fraud?'].map(fraud_encoding)\n",
    "display(data['Is Fraud?'].unique())\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe58943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-1 encoding of \"Has Chip\" \n",
    "has_chip_encoding = {'NO':0, 'YES':1}\n",
    "data['Has Chip'] = data['Has Chip'].map(has_chip_encoding)\n",
    "unique_values = data['Has Chip'].unique()\n",
    "print(f'Has Chip unique values: {unique_values}')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-1 encoding of \"Gender\" \n",
    "gender_encoding = {'Male':0, 'Female':1}\n",
    "data['Gender'] = data['Gender'].map(gender_encoding)\n",
    "unique_values = data['Gender'].unique()\n",
    "print(f'Gender unique values: {unique_values}')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b36db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Card Brand value counts:')\n",
    "display(data['Card Brand'].value_counts())\n",
    "print('Card Brand frequencies:')\n",
    "display(data['Card Brand'].value_counts() / data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Proportion of fraud by Card Brand:')\n",
    "display(data.loc[data['Is Fraud?']==1, 'Card Brand'].value_counts() / data['Card Brand'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT ENCODING for the different card brands\n",
    "one_hot_encoder = OneHotEncoder(sparse=False).fit(np.array(data['Card Brand']).reshape(-1,1))\n",
    "new_columns = [col[3:] for col in one_hot_encoder.get_feature_names()]\n",
    "data[new_columns] = one_hot_encoder.transform(np.array(data['Card Brand']).reshape(-1,1))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c229cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Card Type frequencies:')\n",
    "display(data['Card Type'].value_counts() / data.shape[0])\n",
    "\n",
    "print('Proportion of fraud by Card Type:')\n",
    "display(data.loc[data['Is Fraud?']==1, 'Card Type'].value_counts() / data['Card Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6841d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT ENCODING for the different card types\n",
    "one_hot_encoder = OneHotEncoder(sparse=False).fit(np.array(data['Card Type']).reshape(-1,1))\n",
    "new_columns = [col[3:] for col in one_hot_encoder.get_feature_names()]\n",
    "data[new_columns] = one_hot_encoder.transform(np.array(data['Card Type']).reshape(-1,1))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e95c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change CREDIT LIMIT from string to float\n",
    "data['Credit Limit'] = data['Credit Limit'].str.replace('$','').astype(float)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808dfd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-1 encoding of \"Card on Dark Web\" \n",
    "dark_web_encoding = {'No':0, 'Yes':1}\n",
    "data['Card on Dark Web'] = data['Card on Dark Web'].map(dark_web_encoding)\n",
    "unique_values = data['Card on Dark Web'].unique()\n",
    "print(f'Card on Dark Web unique values: {unique_values}')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172dfe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'Per Capita Income - Zipcode', 'Yearly Income - Person' and 'Total Debt' from string to float\n",
    "data['Per Capita Income - Zipcode'] = data['Per Capita Income - Zipcode'].str.replace('$','').astype(float)\n",
    "data['Yearly Income - Person'] = data['Yearly Income - Person'].str.replace('$','').astype(float)\n",
    "data['Total Debt'] = data['Total Debt'].str.replace('$','').astype(float)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv\n",
    "data_path = os.path.join(project_root, 'data/preprocessed_data_v001.csv')\n",
    "data.to_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a subset of the data as a more light weight development data version\n",
    "data_subset = (data\n",
    "               .sample(1000000, random_state=42)\n",
    "               .sort_values(by='Datetime')\n",
    "               .reset_index(drop=True)\n",
    "              )\n",
    "\n",
    "data_path = os.path.join(project_root, 'data/preprocessed_data_small_v001.csv')\n",
    "data_subset.to_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3504e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-engineering-task-DthksosK-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
